{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JasonD28/CS-175/blob/master/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Report for CS 175, Spring 2020\n",
    "**Project Title:** Water Filled Lung Detector\n",
    "\n",
    "**Project Number:** Group 14\n",
    "\n",
    "**Student Name(s)**\n",
    "\n",
    "Allan Tran, 61735904. allannt@uci.edu\n",
    "\n",
    "Jason Davis, 22336416, jasonbd@uci.edu\n",
    "\n",
    "Eva Dai, 94015611, ydai8@uci.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load any source code we need and import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/v0.5.1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'vision' already exists and is not an empty directory.\n",
      "Already on 'v0.5.1'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Using PyTorch helper functions to simplify training\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "cd vision\n",
    "git checkout v0.5.1\n",
    "\n",
    "cp references/detection/utils.py ../\n",
    "cp references/detection/engine.py ../\n",
    "cp references/detection/transforms.py ../\n",
    "cp references/detection/coco_eval.py ../\n",
    "cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'cocoapi' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "git clone https://github.com/cocodataset/cocoapi.git\n",
    "cd cocoapi\n",
    "cp PythonAPI/pycocotools D:/Python368/dist-packages/ -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dijiZdpvBDmj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from src.dataset import PneumoniaDataset\n",
    "#from engine import train_one_epoch, evaluate\n",
    "#from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "#from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from src.classifier import Classifier\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.nn.functional import relu as Relu\n",
    "from torch import sigmoid\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier:\n",
    "\n",
    "Here we start to load the classifier model and train it with a small sample of our data for demostration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (convInput): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv32to64): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv64to128): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv128): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linearto128): Linear(in_features=2097152, out_features=128, bias=True)\n",
       "  (linearto1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier();\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PneumoniaDataset(root, True)\n",
    "validation_dataset = PneumoniaDataset(root, True)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:20])\n",
    "validation_dataset = torch.utils.data.Subset(validation_dataset, indices[20:])\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=1, shuffle=True, num_workers=1,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "validation_data_loader = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=1, shuffle=False, num_workers=2,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "\n",
    "test_dataset = PneumoniaDataset(root, True, 'test')\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False, num_workers=2,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "loss_fn = nn.BCEWithLogitsLoss().type(gpu_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, dtype, model, loss_fn, optimizer, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, (image, target) in enumerate(train_data):\n",
    "            imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
    "            x_var = Variable(imgs.type(dtype))\n",
    "            l = []\n",
    "            for tar in target:\n",
    "              if len(tar['labels']) > 1:\n",
    "                # temp = [list(tar['labels'])[0]]\n",
    "                l.append([1])\n",
    "              else:\n",
    "                if tar['labels'] == 2:\n",
    "                  l.append([1])\n",
    "                else:\n",
    "                  l.append([0])\n",
    "            y_var = torch.tensor(l).cuda() # Variable(labels.type(dtype).cuda())\n",
    "            scores = model(imgs.cuda())\n",
    "            loss = loss_fn(scores, y_var.float())\n",
    "            if (t + 1) % 5 == 0:\n",
    "              print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "              print(y_var)\n",
    "              print(scores)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "t = 5, loss = 0.0010\n",
      "tensor([[0]], device='cuda:0')\n",
      "tensor([[-6.9146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "t = 10, loss = 0.0000\n",
      "tensor([[0]], device='cuda:0')\n",
      "tensor([[-26.1347]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "t = 15, loss = 0.0000\n",
      "tensor([[0]], device='cuda:0')\n",
      "tensor([[-21.0783]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "t = 20, loss = 0.3503\n",
      "tensor([[0]], device='cuda:0')\n",
      "tensor([[-0.8688]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "train(data_loader, gpu_dtype, model, loss_fn, optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training, we can check the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader):\n",
    "    \"\"\"if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\"\"\"  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for t, (image, target) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "          imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
    "          l = []\n",
    "          metadata = []\n",
    "          for tar in target:\n",
    "            if len(tar['labels']) > 1:\n",
    "              l.append([1])\n",
    "            else:\n",
    "              if tar['labels'] == 2:\n",
    "                l.append([1])\n",
    "              else:\n",
    "                l.append([0])\n",
    "            metadata.append([tar['position']])\n",
    "          l = torch.tensor(l)\n",
    "        raw_scores = sigmoid(model(imgs.cuda()))\n",
    "        scores = torch.tensor([int(raw_scores > 0.37)])\n",
    "        num_correct += (scores == l).sum()\n",
    "        num_samples += scores.size(0)\n",
    "        if (t + 1) % 1 == 0:\n",
    "            print('t = %d, num_correct = %d, num_samples = %d' % (t + 1, num_correct, num_samples))\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 1, num_correct = 0, num_samples = 1\n",
      "t = 2, num_correct = 1, num_samples = 2\n",
      "t = 3, num_correct = 2, num_samples = 3\n",
      "t = 4, num_correct = 2, num_samples = 4\n",
      "t = 5, num_correct = 3, num_samples = 5\n",
      "t = 6, num_correct = 4, num_samples = 6\n",
      "Got 4 / 6 correct (66.67)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(model, validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the predictions into a csv file. But for demostration, here we'll print out the predictions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(model, loader, dataset):\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    pIds = []\n",
    "    predictions = []\n",
    "    for index, (image, target) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "          imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
    "        scores =  torch.tensor([int(sigmoid(model(imgs.cuda())) > 0.37)])\n",
    "        patientId = dataset.imgs[index][:-4]\n",
    "        p = scores.numpy()[0]\n",
    "        pIds.append(patientId)\n",
    "        predictions.append(p)\n",
    "\n",
    "    d = {'patientId': pIds, 'pred': predictions}\n",
    "    #df = pd.DataFrame(data=d)\n",
    "    #path = 'drive/My Drive/cs-175-project/predictions/classifier_w_metadata_prediction.csv'\n",
    "    #df.to_csv(path, index=False)\n",
    "    print(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patientId': ['0000a175-0e68-4ca4-b1af-167204a7e0bc', '0005d3cc-3c3f-40b9-93c3-46231c3eb813', '000686d7-f4fc-448d-97a0-44fa9c5d3aa6', '000e3a7d-c0ca-4349-bb26-5af2d8993c3d', '00100a24-854d-423d-a092-edcf6179e061', '0015597f-2d69-4bc7-b642-5b5e01534676', '001b0c51-c7b3-45c1-9c17-fa7594cab96e', '0022bb50-bf6c-4185-843e-403a9cc1ea80', '00271e8e-aea8-4f0a-8a34-3025831f1079', '0028450f-5b8e-4695-9416-8340b6f686b0'], 'pred': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "save_preds(model, test_data_loader, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the validation and test predictions above, we can see the accuracy is very low. It is caused by the small number of the training data we have in this submission. During the actual project, we ran on the entire dataset of 26k images, which would result in a much higher accuracy of 90.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqy/cIC8u4Sv0qyvCe/CVW",
   "include_colab_link": true,
   "name": "Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
