{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faster_testing.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOZ8Awu+aGlk57zv3loKRcr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonD28/CS-175/blob/master/model/faster_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjifLVJnaJk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1db69135-bee0-48a7-f435-7d0a5d80ce7b"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDHJ4bPUaUJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55f7dd0f-ebfb-4f6f-bd98-b2005a9ef2c8"
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz2hIih_aic6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "999d75d9-893a-474c-f0d7-8efa885ecb05"
      },
      "source": [
        "%%shell\n",
        "git clone https://github.com/JasonD28/CS-175.git\n",
        "cd CS-175\n",
        "cp model/dataset.py  ../"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CS-175' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4dj815acMVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d1b79e71-a19f-40b1-c0ed-2d04661f0aa7"
      },
      "source": [
        "%%shell\n",
        "# Using PyTorch helper functions to simplify training\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.5.1\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "Already on 'v0.5.1'\n",
            "Your branch is up to date with 'origin/v0.5.1'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wemyzqZ9amW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import utils\n",
        "from torch import optim\n",
        "import torchvision\n",
        "\n",
        "from dataset import PneumoniaDataset\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "root = \"drive/My Drive/cs-175-project/cs-175-data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTLt0zDcbAqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44f48afe-530a-488a-e8a2-e8e0be03226f"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=3)\n",
        "model.load_state_dict(torch.load('drive/My Drive/cs-175-project/model_checkpoints/eighth_try_model.pt'))\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign()\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDZyPyX5bOLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = PneumoniaDataset(root, True, 'test')\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=1, shuffle=False, num_workers=4,\n",
        "        collate_fn=utils.collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxfzLMPK_k3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "final = pd.DataFrame(columns = ['patientId', 'PredictionString'])\n",
        "confidence = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2if3981mca_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "dce901dd-4c92-4b79-fe0d-30328a587fdd"
      },
      "source": [
        "model.eval()\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "predictions = []\n",
        "for i, (x, y) in enumerate(test_loader):\n",
        "  with torch.no_grad():\n",
        "    images = list(image.to(device) for image in x)\n",
        "  pred = model(images)[0]\n",
        "  preds = pred\n",
        "  pred_str = []\n",
        "  for index, score in enumerate(preds['scores'].tolist()):\n",
        "    if score >= confidence:\n",
        "      boxes = preds['boxes'][index].tolist()\n",
        "      if preds['labels'][index] == 2:\n",
        "        pred_str.extend([score, boxes[0], boxes[1], boxes[2] - boxes[0], boxes[3] - boxes[1]])\n",
        "  pred_str = [str(x) for x in pred_str]\n",
        "  pred_str = ' '.join(pred_str)\n",
        "  final = final.append({'patientId': testset.imgs[i][:-4], 'PredictionString': pred_str}, ignore_index=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWY_6xmvf7S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "# final = pd.DataFrame(columns = ['patientId', 'PredictionString'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McCi7dZ4pe5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confidence = 0.5\n",
        "# for img_id, preds in predictions:\n",
        "#   preds = preds[0]\n",
        "#   pred_str = []\n",
        "#   for index, score in enumerate(preds['scores'].tolist()):\n",
        "#     if score >= confidence:\n",
        "#       boxes = preds['boxes'][index].tolist()\n",
        "#       # if preds['labels'][index] == 2:\n",
        "#         pred_str.extend([score, boxes[0], boxes[1], boxes[2] - boxes[0], boxes[3] - boxes[1]])\n",
        "#   pred_str = [str(x) for x in pred_str]\n",
        "#   pred_str = ' '.join(pred_str)\n",
        "#   final = final.append({'patientId': img_id, 'PredictionString': pred_str}, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8jlreEAqeBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "7201bc4c-f526-4579-947d-5ccd35c73ce3"
      },
      "source": [
        "print(final)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 patientId                                   PredictionString\n",
            "0     0000a175-0e68-4ca4-b1af-167204a7e0bc                                                   \n",
            "1     0005d3cc-3c3f-40b9-93c3-46231c3eb813                                                   \n",
            "2     000686d7-f4fc-448d-97a0-44fa9c5d3aa6                                                   \n",
            "3     000e3a7d-c0ca-4349-bb26-5af2d8993c3d                                                   \n",
            "4     00100a24-854d-423d-a092-edcf6179e061  0.5938289165496826 529.087158203125 362.260467...\n",
            "...                                    ...                                                ...\n",
            "2995  c1e88810-9e4e-4f39-9306-8d314bfc1ff1                                                   \n",
            "2996  c1ec035b-377b-416c-a281-f868b7c9b6c3                                                   \n",
            "2997  c1ef5b66-0fd7-49d1-ae6b-5af84929414b                                                   \n",
            "2998  c1ef6724-f95f-40f1-b25b-de806d9bc39d                                                   \n",
            "2999  c1f55e7e-4065-4dc0-993e-a7c1704c6036                                                   \n",
            "\n",
            "[3000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE-c4y-MwpmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.to_csv('drive/My Drive/cs-175-project/predictions/faster_prediction.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hy3OElQBkhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}