{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonD28/CS-175/blob/master/scripts/alternate_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3RyiJHima87",
        "colab_type": "code",
        "outputId": "484444e6-85d2-4f92-8969-1381439e9d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2m97kwSnFuN",
        "colab_type": "code",
        "outputId": "b87481fa-d5c2-4c37-d96e-18d7c5aba293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dDw0fmio5TD",
        "colab_type": "code",
        "outputId": "ac02a430-8ddc-4377-b10d-f7a2bd042abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%shell\n",
        "git clone https://github.com/JasonD28/CS-175.git\n",
        "cd CS-175\n",
        "cp model/dataset.py  ../"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CS-175' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjNmEHEcsfzF",
        "colab_type": "code",
        "outputId": "784c7f6a-063a-42c6-df22-86e2ea9d5e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.5.1\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "Already on 'v0.5.1'\n",
            "Your branch is up to date with 'origin/v0.5.1'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEb5acNeo9B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from dataset import PneumoniaDataset\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from torch.nn.functional import relu as Relu\n",
        "from torch import sigmoid\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import timeit\n",
        "\n",
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C40esjJEcT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Flatten(x):\n",
        "    N, C, H, W = x.size() # read in N, C, H, W\n",
        "    return x.view(N, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdsPiXkBpGXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        ksize = 3\n",
        "        netPadding = (ksize-1)//2\n",
        "        self.convInput = nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32 = nn.Conv2d(32, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32to64 = nn.Conv2d(32, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64 = nn.Conv2d(64, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to128 = nn.Conv2d(64, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128 = nn.Conv2d(128, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to256 = nn.Conv2d(128, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256 = nn.Conv2d(256, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256to128 = nn.Conv2d(256, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to64 = nn.Conv2d(128, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to1 = nn.Conv2d(64, 1, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
        "        self.upsampling = nn.Upsample(scale_factor=(2,2))\n",
        "        self.linearto2048 = nn.Linear(4096,2048)\n",
        "        self.linearto3 = nn.Linear(2048,3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = model(x) # Not sure what this does\n",
        "        x = Relu(self.convInput(x), inplace=True)\n",
        "        x = Relu(self.conv32(x), inplace=True)\n",
        "        poolX = self.pooling(x)\n",
        "        \n",
        "        x2 = Relu(self.conv32to64(poolX), inplace=True)\n",
        "        x2 = Relu(self.conv64(x2), inplace=True)\n",
        "        poolX2 = self.pooling(x2)\n",
        "\n",
        "        x3 = Relu(self.conv64(poolX2), inplace=True)\n",
        "        x3 = Relu(self.conv64(x3), inplace=True)\n",
        "        poolX3 = self.pooling(x3)\n",
        "        # print(f'Pool 3: {poolX3.shape}')\n",
        "        \n",
        "        x4 = Relu(self.conv64to128(poolX3), inplace=True)\n",
        "        x4 = Relu(self.conv128(x4), inplace=True)\n",
        "        poolX4 = self.pooling(x4)\n",
        "        \n",
        "        x5 = Relu(self.conv128to256(poolX4), inplace=True)\n",
        "        \n",
        "        up6 = self.upsampling(x5)\n",
        "        x6 = Relu(self.conv256(up6), inplace=True)\n",
        "        x6 = Relu(self.conv256(x6), inplace=True)\n",
        "        poolX6 = x6 #self.pooling(x6)\n",
        "        # print(f'Pool 6: {poolX6.shape}')\n",
        "        x6 = Relu(self.conv256(poolX6), inplace=True)\n",
        "        \n",
        "        up7 = x6 #self.upsampling(x6)\n",
        "        x7 = Relu(self.conv256(up7), inplace=True)\n",
        "        x7 = Relu(self.conv256(x7), inplace=True)\n",
        "        poolX7 = self.pooling(x7)\n",
        "        x7 = Relu(self.conv256(poolX7), inplace=True)\n",
        "        \n",
        "        up8 = self.upsampling(x7)\n",
        "        x8 = Relu(self.conv256to128(up8), inplace=True)\n",
        "        x8 = Relu(self.conv128(x8), inplace=True)\n",
        "        poolX8 = x8  #self.pooling(x8)\n",
        "        # print(f'Pool 8: {poolX8.shape}')\n",
        "        x8 = Relu(self.conv128(poolX8), inplace=True)\n",
        "        \n",
        "        up9 = x8 #self.upsampling(x8)\n",
        "        x9 = Relu(self.conv128to64(up9), inplace=True)\n",
        "        x9 = Relu(self.conv64(x9), inplace=True)\n",
        "        poolX9 = self.pooling(x9)\n",
        "        x9 = Relu(self.conv64(poolX9), inplace=True)\n",
        "        \n",
        "        x10 = Flatten(self.conv64to1(x9))\n",
        "        # print(f'Final Layer: {self.conv64to1(x9).shape}')\n",
        "        x11 = Relu(self.linearto2048(x10), inplace=True)\n",
        "        x12 = self.linearto3(x11)\n",
        "        # x13 = sigmoid(x12)\n",
        "        # x10 = sigmoid(self.conv64to1(x9))\n",
        "        \n",
        "        return x12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpSviSegDRkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        ksize = 3\n",
        "        netPadding = (ksize-1)//2\n",
        "        self.convInput = nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32 = nn.Conv2d(32, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32to64 = nn.Conv2d(32, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64 = nn.Conv2d(64, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to128 = nn.Conv2d(64, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128 = nn.Conv2d(128, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to256 = nn.Conv2d(128, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256 = nn.Conv2d(256, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256to128 = nn.Conv2d(256, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to64 = nn.Conv2d(128, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to1 = nn.Conv2d(64, 1, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
        "        self.upsampling = nn.Upsample(scale_factor=(2,2))\n",
        "        self.linearto128 = nn.Linear(131072,128)\n",
        "        self.linearto2048 = nn.Linear(4096,2048)\n",
        "        self.linearto3 = nn.Linear(2048,3)\n",
        "        self.linearto1 = nn.Linear(128,1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "        # out = model(x) # Not sure what this does\n",
        "        x = Relu(self.convInput(x), inplace=True)\n",
        "        x = Relu(self.conv32(x), inplace=True)\n",
        "        poolX = self.pooling(x)\n",
        "        \n",
        "        x2 = self.dropout(poolX)\n",
        "        x2 = Relu(self.conv32to64(x2), inplace=True)\n",
        "        x2 = Relu(self.conv64(x2), inplace=True)\n",
        "        poolX2 = self.pooling(x2)\n",
        "\n",
        "        x3 = self.dropout(poolX2)\n",
        "        \n",
        "        x4 = Relu(self.conv64to128(x3), inplace=True)\n",
        "        x4 = Relu(self.conv128(x4), inplace=True)\n",
        "        poolX4 = self.pooling(x4)\n",
        "        #print(poolX4.shape)\n",
        "        x5 = self.dropout(poolX4)\n",
        "        #print(x5.shape)\n",
        "\n",
        "        x6 = Relu(self.conv128to256(x5), inplace=True)\n",
        "        x6 = Relu(self.conv256(x6), inplace=True)\n",
        "        poolX6 = self.pooling(x6)\n",
        "        x7 = self.dropout(poolX6)\n",
        "        x7 = Relu(self.conv256to128(x7), inplace=True)\n",
        "        x7 = Relu(self.conv128(x7), inplace=True)\n",
        "        poolX7 = self.pooling(x7)\n",
        "        x8 = self.dropout(poolX7)\n",
        "\n",
        "        \n",
        "        x9 = Flatten(x8)\n",
        "        \n",
        "        x10 = Relu(self.linearto128(x9), inplace=True)\n",
        "        x10 = self.dropout(x10)\n",
        "        \n",
        "        #x7 = sigmoid(self.linearto1(x6))\n",
        "        x11 = self.linearto1(x10)\n",
        "        return x11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-z85WnQqm-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"drive/My Drive/cs-175-project/cs-175-data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaEOT9tqzPx",
        "colab_type": "code",
        "outputId": "a68eb6ee-1555-4652-d8ef-1228c55de9b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "model = Classifier();\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (convInput): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32to64): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64to128): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128to256): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv256): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv256to128): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128to64): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64to1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pooling2): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (upsampling): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
              "  (linearto128): Linear(in_features=131072, out_features=128, bias=True)\n",
              "  (linearto2048): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (linearto3): Linear(in_features=2048, out_features=3, bias=True)\n",
              "  (linearto1): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7deG3lprGQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = PneumoniaDataset(root, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvr-6yGW4smK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = PneumoniaDataset(root, True)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-1000])\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, indices[-1000:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=2, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "lr_step = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opz_nduVr--o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_data, dtype, model, loss_fn, optimizer, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "        #print(train_data.shape)\n",
        "        for t, (image, target) in enumerate(train_data):\n",
        "            #print(image)\n",
        "            # images = list(img for img in image)\n",
        "            imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
        "            x_var = Variable(imgs.type(dtype))\n",
        "            l = []\n",
        "            for tar in target:\n",
        "              # print(len(tar['labels']))\n",
        "              if len(tar['labels']) > 1:\n",
        "                temp = [list(tar['labels'])[0]]\n",
        "                l.append([1])\n",
        "              else:\n",
        "                if tar['labels'] == 2:\n",
        "                  l.append([1])\n",
        "                else:\n",
        "                  l.append([0])\n",
        "            # print(l)\n",
        "            y_var = torch.tensor(l).cuda() # Variable(labels.type(dtype).cuda())\n",
        "            print(y_var)\n",
        "            \n",
        "            scores = model(imgs.cuda())\n",
        "            print(scores)\n",
        "            loss = loss_fn(scores, y_var.float())\n",
        "            if (t + 1) % 100 == 0:\n",
        "              print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
        "              print(y_var)\n",
        "              print(scores)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gy3QlPBs1O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "loss_fn = nn.BCEWithLogitsLoss().type(gpu_dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Q7lCqLtguQ",
        "colab_type": "code",
        "outputId": "a1408e46-1cff-4cdd-f263-9f07f1038cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(data_loader, gpu_dtype, model, loss_fn, optimizer, 1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 1\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.0310],\n",
            "        [-0.0314]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[ 0.0297],\n",
            "        [-0.0602]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.9774],\n",
            "        [-1.7302]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-15.8579],\n",
            "        [-18.0672]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-124.6952],\n",
            "        [-132.9042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-25.2482],\n",
            "        [-24.2904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-3.3206],\n",
            "        [-2.8577]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.2383],\n",
            "        [-0.8735]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.7582],\n",
            "        [-1.1072]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7582],\n",
            "        [-0.8210]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6073],\n",
            "        [-0.7035]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.4745],\n",
            "        [-0.3297]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.4279],\n",
            "        [-0.3235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.3968],\n",
            "        [-0.3497]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.2874],\n",
            "        [-0.3158]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.1914],\n",
            "        [-0.2268]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.3316],\n",
            "        [-0.2539]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.1906],\n",
            "        [-0.1943]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.1762],\n",
            "        [-0.2221]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.2591],\n",
            "        [-0.1775]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.3048],\n",
            "        [-0.3191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.4934],\n",
            "        [-0.3337]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6902],\n",
            "        [-0.3782]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.4865],\n",
            "        [-0.6255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6393],\n",
            "        [-0.9117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0128],\n",
            "        [-0.8178]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.0457],\n",
            "        [-1.0235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7424],\n",
            "        [-0.8768]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7407],\n",
            "        [-1.1964]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0397],\n",
            "        [-0.6225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.3113],\n",
            "        [-1.1815]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.3952],\n",
            "        [-1.0600]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.3562],\n",
            "        [-1.3034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1318],\n",
            "        [-1.3349]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.5853],\n",
            "        [-1.2779]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.2107],\n",
            "        [-1.7924]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.7393],\n",
            "        [-1.7644]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.9148],\n",
            "        [-1.7099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.5137],\n",
            "        [-1.8486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-2.2002],\n",
            "        [-1.8303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.9639],\n",
            "        [-2.1453]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.5354],\n",
            "        [-1.8639]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.7269],\n",
            "        [-1.8254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.9766],\n",
            "        [-1.8532]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.8442],\n",
            "        [-1.9226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.9541],\n",
            "        [-2.0153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.8833],\n",
            "        [-2.2087]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.9831],\n",
            "        [-1.7894]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.3981],\n",
            "        [-1.8262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.5273],\n",
            "        [-0.9809]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.2753],\n",
            "        [-0.7558]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.3736],\n",
            "        [-1.3010]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.1406],\n",
            "        [-0.6526]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1494],\n",
            "        [-1.1894]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1209],\n",
            "        [-0.9152]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.8752],\n",
            "        [-1.1077]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7363],\n",
            "        [-0.8790]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.5953],\n",
            "        [-0.8379]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6641],\n",
            "        [-0.8420]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.8799],\n",
            "        [-1.0096]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9226],\n",
            "        [-0.9649]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.5777],\n",
            "        [-0.9528]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.6689],\n",
            "        [-0.8788]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6469],\n",
            "        [-0.8844]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6916],\n",
            "        [-0.9875]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8985],\n",
            "        [-0.6021]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7101],\n",
            "        [-0.9230]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.5906],\n",
            "        [-0.7440]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7559],\n",
            "        [-0.7389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8814],\n",
            "        [-0.8255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.8469],\n",
            "        [-1.0621]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.8130],\n",
            "        [-0.9265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9246],\n",
            "        [-0.7174]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8403],\n",
            "        [-0.8586]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.6470],\n",
            "        [-0.6732]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.1460],\n",
            "        [-1.0958]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9351],\n",
            "        [-0.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1462],\n",
            "        [-0.9440]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.3112],\n",
            "        [-0.6881]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.0753],\n",
            "        [-1.0285]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.7992],\n",
            "        [-1.3762]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0867],\n",
            "        [-1.3117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8083],\n",
            "        [-0.8177]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1088],\n",
            "        [-1.1405]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.3444],\n",
            "        [-0.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0023],\n",
            "        [-0.9097]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.9403],\n",
            "        [-1.0857]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.8593],\n",
            "        [-0.9062]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7436],\n",
            "        [-1.1247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0810],\n",
            "        [-0.9187]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9666],\n",
            "        [-1.1688]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9498],\n",
            "        [-0.9905]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9934],\n",
            "        [-1.1819]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.7429],\n",
            "        [-1.2296]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1704],\n",
            "        [-0.8358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1853],\n",
            "        [-0.7213]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.2214],\n",
            "        [-1.1399]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.4234],\n",
            "        [-1.0715]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7097],\n",
            "        [-0.5533]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.1700],\n",
            "        [-0.9447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 100, loss = 0.7717\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.1700],\n",
            "        [-0.9447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.0088],\n",
            "        [-1.1517]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8991],\n",
            "        [-1.0550]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9437],\n",
            "        [-0.9883]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.9921],\n",
            "        [-0.7129]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.5978],\n",
            "        [-0.8024]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8022],\n",
            "        [-0.8804]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.9371],\n",
            "        [-0.9467]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9352],\n",
            "        [-0.8875]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.8752],\n",
            "        [-0.6353]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8421],\n",
            "        [-0.7135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.5606],\n",
            "        [-0.2493]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9054],\n",
            "        [-0.9156]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.8649],\n",
            "        [-0.6805]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.4805],\n",
            "        [-0.4921]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.4379],\n",
            "        [-0.8011]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-0.7110],\n",
            "        [-1.0336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.1046],\n",
            "        [-0.6486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0883],\n",
            "        [-0.9855]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9474],\n",
            "        [-0.8814]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0356],\n",
            "        [-1.2407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.3337],\n",
            "        [-1.0771]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.4104],\n",
            "        [-1.1838]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.7227],\n",
            "        [-1.3465]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-0.9260],\n",
            "        [-0.9698]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.2823],\n",
            "        [-1.3988]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[1],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.5679],\n",
            "        [-1.5680]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [1]], device='cuda:0')\n",
            "tensor([[-1.1763],\n",
            "        [-1.1616]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.0239],\n",
            "        [-1.2561]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([[-1.6487],\n",
            "        [-1.1971]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-355a911143dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-a869f4ddd109>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, dtype, model, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print(train_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m#print(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# images = list(img for img in image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWU4kn1TXk6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy(model, loader):\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    for x, y in loader:\n",
        "        with torch.no_grad():\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}