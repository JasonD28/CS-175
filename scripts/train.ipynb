{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonD28/CS-175/blob/master/scripts/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3RyiJHima87",
        "colab_type": "code",
        "outputId": "484634a3-61b4-43eb-9c04-478a4c1f8c06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2m97kwSnFuN",
        "colab_type": "code",
        "outputId": "e3952140-9ebd-4638-dede-e11e5e834b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 82kB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dDw0fmio5TD",
        "colab_type": "code",
        "outputId": "978c4970-e5ad-49f7-b08a-1fe44fa5166b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%shell\n",
        "git clone https://github.com/JasonD28/CS-175.git\n",
        "cd CS-175\n",
        "cp model/dataset.py  ../"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS-175'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 131 (delta 62), reused 48 (delta 17), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (131/131), 930.90 KiB | 2.61 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEb5acNeo9B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from dataset import PneumoniaDataset\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from torch.nn.functional import relu as Relu\n",
        "from torch.nn.functional import sigmoid\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import timeit\n",
        "\n",
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdsPiXkBpGXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        ksize = 3\n",
        "        netPadding = (ksize-1)//2\n",
        "        self.convInput = nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32 = nn.Conv2d(32, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32to64 = nn.Conv2d(32, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64 = nn.Conv2d(64, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to128 = nn.Conv2d(64, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128 = nn.Conv2d(128, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to256 = nn.Conv2d(128, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256 = nn.Conv2d(256, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256to128 = nn.Conv2d(256, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to64 = nn.Conv2d(128, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to1 = nn.Conv2d(64, 1, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.upsampling = nn.Upsample(scale_factor=(2,2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = model(x) # Not sure what this does\n",
        "        x = Relu(self.convInput(x), inplace=True)\n",
        "        x = Relu(self.conv32(x), inplace=True)\n",
        "        poolX = self.pooling(x)\n",
        "        \n",
        "        x2 = Relu(self.conv32to64(poolX), inplace=True)\n",
        "        x2 = Relu(self.conv64(x2), inplace=True)\n",
        "        poolX2 = self.pooling(x2)\n",
        "\n",
        "        x3 = Relu(self.conv64(poolX2), inplace=True)\n",
        "        x3 = Relu(self.conv64(x3), inplace=True)\n",
        "        poolX3 = self.pooling(x3)\n",
        "        \n",
        "        x4 = Relu(self.conv64to128(poolX3), inplace=True)\n",
        "        x4 = Relu(self.conv128(x4), inplace=True)\n",
        "        poolX4 = self.pooling(x4)\n",
        "        \n",
        "        x5 = Relu(self.conv128to256(poolX4), inplace=True)\n",
        "        \n",
        "        up6 = self.upsampling(x5)\n",
        "        x6 = Relu(self.conv256(up6), inplace=True)\n",
        "        x6 = Relu(self.conv256(x6), inplace=True)\n",
        "        poolX6 = self.pooling(x6)\n",
        "        merge6 = poolX6 #torch.cat((x4,poolX6),-1)\n",
        "        x6 = Relu(self.conv256(merge6), inplace=True)\n",
        "        \n",
        "        up7 = self.upsampling(x6)\n",
        "        x7 = Relu(self.conv256(up7), inplace=True)\n",
        "        x7 = Relu(self.conv256(x7), inplace=True)\n",
        "        poolX7 = self.pooling(x7)\n",
        "        merge7 = poolX7 #torch.cat((x3,poolX7),-1)\n",
        "        x7 = Relu(self.conv256(merge7), inplace=True)\n",
        "        \n",
        "        up8 = self.upsampling(x7)\n",
        "        x8 = Relu(self.conv256to128(up8), inplace=True)\n",
        "        x8 = Relu(self.conv128(x8), inplace=True)\n",
        "        poolX8 = self.pooling(x8)\n",
        "        merge8 = poolX8 #torch.cat((x2,poolX8),-1)\n",
        "        x8 = Relu(self.conv128(merge8), inplace=True)\n",
        "        \n",
        "        up9 = self.upsampling(x8)\n",
        "        x9 = Relu(self.conv128to64(up9), inplace=True)\n",
        "        x9 = Relu(self.conv64(x9), inplace=True)\n",
        "        poolX9 = self.pooling(x9)\n",
        "        merge9 = poolX9 #torch.cat((x1,poolX9),-1)\n",
        "        x9 = Relu(self.conv64(merge9), inplace=True)\n",
        "        \n",
        "        x10 = sigmoid(self.conv64to1(x9), inplace=True)\n",
        "        \n",
        "        return x10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-z85WnQqm-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"drive/My Drive/cs-175-data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaEOT9tqzPx",
        "colab_type": "code",
        "outputId": "72f47e1c-8427-40d8-abda-fe241fc04906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "model = NeuralNet();\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (convInput): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32to64): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64to128): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128to256): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv256): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv256to128): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128to64): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64to1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (upsampling): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjNmEHEcsfzF",
        "colab_type": "code",
        "outputId": "bffa887f-baed-487f-b1ac-f2e6823482eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.5.1\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 8311 (delta 3), reused 3 (delta 0), pack-reused 8297\u001b[K\n",
            "Receiving objects: 100% (8311/8311), 10.23 MiB | 6.85 MiB/s, done.\n",
            "Resolving deltas: 100% (5706/5706), done.\n",
            "Branch 'v0.5.1' set up to track remote branch 'v0.5.1' from 'origin'.\n",
            "Switched to a new branch 'v0.5.1'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7deG3lprGQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = PneumoniaDataset(root, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvr-6yGW4smK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = PneumoniaDataset(root, True)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, indices[-50:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=2, shuffle=True, num_workers=0,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=False, num_workers=0,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
        "lr_step = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opz_nduVr--o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_data, dtype, model, loss_fn, optimizer, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "        #print(train_data.shape)\n",
        "        for t, (image, target) in enumerate(train_data):\n",
        "            #print(image)\n",
        "            images = list(img for img in image)\n",
        "\n",
        "            #x_var = Variable(images.type(dtype))\n",
        "            l = []\n",
        "            for t in target:\n",
        "              boxes, masks, labels = t['boxes'], t['masks'], t['labels']\n",
        "              l.append(labels)\n",
        "            print(l)\n",
        "            y_var = torch.tensor(l) # Variable(labels.type(dtype).cuda())\n",
        "            print(images)\n",
        "            timage = torch.tensor(images)\n",
        "            scores = model(timage)\n",
        "\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            if (t + 1) % print_every == 0:\n",
        "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gy3QlPBs1O9",
        "colab_type": "code",
        "outputId": "6fac959e-ec5c-4f96-ccff-5400746c2be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "train(data_loader, gpu_dtype, model, loss_fn, optimizer, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 1\n",
            "[tensor([0]), tensor([0])]\n",
            "[tensor([[[0.0118, 0.0314, 0.0314,  ..., 0.0118, 0.0078, 0.0039],\n",
            "         [0.0431, 0.0588, 0.0627,  ..., 0.0157, 0.0118, 0.0078],\n",
            "         [0.0314, 0.0471, 0.0510,  ..., 0.0196, 0.0157, 0.0118],\n",
            "         ...,\n",
            "         [0.4235, 0.7451, 0.7333,  ..., 0.6588, 0.6588, 0.3725],\n",
            "         [0.4588, 0.7451, 0.7451,  ..., 0.6627, 0.6784, 0.4314],\n",
            "         [0.2039, 0.4000, 0.3490,  ..., 0.3059, 0.3608, 0.1725]]]), tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0078],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.1725, 0.0824, 0.0039],\n",
            "         ...,\n",
            "         [0.8863, 0.8941, 0.8902,  ..., 0.9098, 0.9059, 0.9255],\n",
            "         [0.8902, 0.9020, 0.9059,  ..., 0.9216, 0.9137, 0.9294],\n",
            "         [0.8941, 0.9137, 0.9216,  ..., 0.9333, 0.9294, 0.9412]]])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4bc6d0875079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgpu_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-c7a956be4bb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, dtype, model, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Variable(labels.type(dtype).cuda())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# torch.tensor(images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Variable data has to be a tensor, but got list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Q7lCqLtguQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}