{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonD28/CS-175/blob/master/scripts/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3RyiJHima87",
        "colab_type": "code",
        "outputId": "e6849314-0fee-432e-8c55-cb3ad0e0a0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2m97kwSnFuN",
        "colab_type": "code",
        "outputId": "d33b5713-5574-4117-910b-25a43ff6963c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dDw0fmio5TD",
        "colab_type": "code",
        "outputId": "08f7f972-6eac-4d6e-d4a3-6eb0f37855fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "%%shell\n",
        "rm -r CS-175\n",
        "git clone https://github.com/JasonD28/CS-175.git\n",
        "cd CS-175\n",
        "cp model/dataset.py  ../"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS-175'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/56)\u001b[K\rremote: Counting objects:   3% (2/56)\u001b[K\rremote: Counting objects:   5% (3/56)\u001b[K\rremote: Counting objects:   7% (4/56)\u001b[K\rremote: Counting objects:   8% (5/56)\u001b[K\rremote: Counting objects:  10% (6/56)\u001b[K\rremote: Counting objects:  12% (7/56)\u001b[K\rremote: Counting objects:  14% (8/56)\u001b[K\rremote: Counting objects:  16% (9/56)\u001b[K\rremote: Counting objects:  17% (10/56)\u001b[K\rremote: Counting objects:  19% (11/56)\u001b[K\rremote: Counting objects:  21% (12/56)\u001b[K\rremote: Counting objects:  23% (13/56)\u001b[K\rremote: Counting objects:  25% (14/56)\u001b[K\rremote: Counting objects:  26% (15/56)\u001b[K\rremote: Counting objects:  28% (16/56)\u001b[K\rremote: Counting objects:  30% (17/56)\u001b[K\rremote: Counting objects:  32% (18/56)\u001b[K\rremote: Counting objects:  33% (19/56)\u001b[K\rremote: Counting objects:  35% (20/56)\u001b[K\rremote: Counting objects:  37% (21/56)\u001b[K\rremote: Counting objects:  39% (22/56)\u001b[K\rremote: Counting objects:  41% (23/56)\u001b[K\rremote: Counting objects:  42% (24/56)\u001b[K\rremote: Counting objects:  44% (25/56)\u001b[K\rremote: Counting objects:  46% (26/56)\u001b[K\rremote: Counting objects:  48% (27/56)\u001b[K\rremote: Counting objects:  50% (28/56)\u001b[K\rremote: Counting objects:  51% (29/56)\u001b[K\rremote: Counting objects:  53% (30/56)\u001b[K\rremote: Counting objects:  55% (31/56)\u001b[K\rremote: Counting objects:  57% (32/56)\u001b[K\rremote: Counting objects:  58% (33/56)\u001b[K\rremote: Counting objects:  60% (34/56)\u001b[K\rremote: Counting objects:  62% (35/56)\u001b[K\rremote: Counting objects:  64% (36/56)\u001b[K\rremote: Counting objects:  66% (37/56)\u001b[K\rremote: Counting objects:  67% (38/56)\u001b[K\rremote: Counting objects:  69% (39/56)\u001b[K\rremote: Counting objects:  71% (40/56)\u001b[K\rremote: Counting objects:  73% (41/56)\u001b[K\rremote: Counting objects:  75% (42/56)\u001b[K\rremote: Counting objects:  76% (43/56)\u001b[K\rremote: Counting objects:  78% (44/56)\u001b[K\rremote: Counting objects:  80% (45/56)\u001b[K\rremote: Counting objects:  82% (46/56)\u001b[K\rremote: Counting objects:  83% (47/56)\u001b[K\rremote: Counting objects:  85% (48/56)\u001b[K\rremote: Counting objects:  87% (49/56)\u001b[K\rremote: Counting objects:  89% (50/56)\u001b[K\rremote: Counting objects:  91% (51/56)\u001b[K\rremote: Counting objects:  92% (52/56)\u001b[K\rremote: Counting objects:  94% (53/56)\u001b[K\rremote: Counting objects:  96% (54/56)\u001b[K\rremote: Counting objects:  98% (55/56)\u001b[K\rremote: Counting objects: 100% (56/56)\u001b[K\rremote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 228 (delta 35), reused 11 (delta 5), pack-reused 172\u001b[K\n",
            "Receiving objects: 100% (228/228), 1.04 MiB | 2.59 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjNmEHEcsfzF",
        "colab_type": "code",
        "outputId": "d05daf2a-9e44-46e9-83a2-bf274d626a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.5.1\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "Already on 'v0.5.1'\n",
            "Your branch is up to date with 'origin/v0.5.1'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEb5acNeo9B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from dataset import PneumoniaDataset\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from torch.nn.functional import relu as Relu\n",
        "from torch import sigmoid\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import timeit\n",
        "\n",
        "import utils\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C40esjJEcT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Flatten(x):\n",
        "    N, C, H, W = x.size() # read in N, C, H, W\n",
        "    return x.view(N, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdsPiXkBpGXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        ksize = 3\n",
        "        netPadding = (ksize-1)//2\n",
        "        self.convInput = nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32 = nn.Conv2d(32, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32to64 = nn.Conv2d(32, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64 = nn.Conv2d(64, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to128 = nn.Conv2d(64, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128 = nn.Conv2d(128, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to256 = nn.Conv2d(128, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256 = nn.Conv2d(256, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256to128 = nn.Conv2d(256, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to64 = nn.Conv2d(128, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to1 = nn.Conv2d(64, 1, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
        "        self.upsampling = nn.Upsample(scale_factor=(2,2))\n",
        "        self.linearto2048 = nn.Linear(4096,2048)\n",
        "        self.linearto3 = nn.Linear(2048,3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = model(x) # Not sure what this does\n",
        "        x = Relu(self.convInput(x), inplace=True)\n",
        "        x = Relu(self.conv32(x), inplace=True)\n",
        "        poolX = self.pooling(x)\n",
        "        \n",
        "        x2 = Relu(self.conv32to64(poolX), inplace=True)\n",
        "        x2 = Relu(self.conv64(x2), inplace=True)\n",
        "        poolX2 = self.pooling(x2)\n",
        "\n",
        "        x3 = Relu(self.conv64(poolX2), inplace=True)\n",
        "        x3 = Relu(self.conv64(x3), inplace=True)\n",
        "        poolX3 = self.pooling(x3)\n",
        "        # print(f'Pool 3: {poolX3.shape}')\n",
        "        \n",
        "        x4 = Relu(self.conv64to128(poolX3), inplace=True)\n",
        "        x4 = Relu(self.conv128(x4), inplace=True)\n",
        "        poolX4 = self.pooling(x4)\n",
        "        \n",
        "        x5 = Relu(self.conv128to256(poolX4), inplace=True)\n",
        "        \n",
        "        up6 = self.upsampling(x5)\n",
        "        x6 = Relu(self.conv256(up6), inplace=True)\n",
        "        x6 = Relu(self.conv256(x6), inplace=True)\n",
        "        poolX6 = x6 #self.pooling(x6)\n",
        "        # print(f'Pool 6: {poolX6.shape}')\n",
        "        x6 = Relu(self.conv256(poolX6), inplace=True)\n",
        "        \n",
        "        up7 = x6 #self.upsampling(x6)\n",
        "        x7 = Relu(self.conv256(up7), inplace=True)\n",
        "        x7 = Relu(self.conv256(x7), inplace=True)\n",
        "        poolX7 = self.pooling(x7)\n",
        "        x7 = Relu(self.conv256(poolX7), inplace=True)\n",
        "        \n",
        "        up8 = self.upsampling(x7)\n",
        "        x8 = Relu(self.conv256to128(up8), inplace=True)\n",
        "        x8 = Relu(self.conv128(x8), inplace=True)\n",
        "        poolX8 = x8  #self.pooling(x8)\n",
        "        # print(f'Pool 8: {poolX8.shape}')\n",
        "        x8 = Relu(self.conv128(poolX8), inplace=True)\n",
        "        \n",
        "        up9 = x8 #self.upsampling(x8)\n",
        "        x9 = Relu(self.conv128to64(up9), inplace=True)\n",
        "        x9 = Relu(self.conv64(x9), inplace=True)\n",
        "        poolX9 = self.pooling(x9)\n",
        "        x9 = Relu(self.conv64(poolX9), inplace=True)\n",
        "        \n",
        "        x10 = Flatten(self.conv64to1(x9))\n",
        "        # print(f'Final Layer: {self.conv64to1(x9).shape}')\n",
        "        x11 = Relu(self.linearto2048(x10), inplace=True)\n",
        "        x12 = self.linearto3(x11)\n",
        "        # x13 = sigmoid(x12)\n",
        "        # x10 = sigmoid(self.conv64to1(x9))\n",
        "        \n",
        "        return x12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpSviSegDRkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        ksize = 3\n",
        "        netPadding = (ksize-1)//2\n",
        "        self.convInput = nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32 = nn.Conv2d(32, 32, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv32to64 = nn.Conv2d(32, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64 = nn.Conv2d(64, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to128 = nn.Conv2d(64, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128 = nn.Conv2d(128, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to256 = nn.Conv2d(128, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256 = nn.Conv2d(256, 256, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv256to128 = nn.Conv2d(256, 128, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv128to64 = nn.Conv2d(128, 64, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.conv64to1 = nn.Conv2d(64, 1, kernel_size=ksize, stride=1, padding=netPadding)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
        "        self.upsampling = nn.Upsample(scale_factor=(2,2))\n",
        "        self.linearto128 = nn.Linear(2097152,128)\n",
        "        self.linearto2048 = nn.Linear(4096,2048)\n",
        "        self.linearto3 = nn.Linear(2048,3)\n",
        "        self.linearto1 = nn.Linear(128,1)\n",
        "        self.linear2to1 = nn.Linear(2,1)\n",
        "        self.linear1to1 = nn.Linear(1,1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x, data):\n",
        "        # out = model(x) # Not sure what this does\n",
        "        x = Relu(self.convInput(x), inplace=True)\n",
        "        x = Relu(self.conv32(x), inplace=True)\n",
        "        poolX = self.pooling(x)\n",
        "        \n",
        "        x2 = self.dropout(poolX)\n",
        "        x2 = Relu(self.conv32to64(x2), inplace=True)\n",
        "        x2 = Relu(self.conv64(x2), inplace=True)\n",
        "        poolX2 = self.pooling(x2)\n",
        "\n",
        "        x3 = self.dropout(poolX2)\n",
        "        \n",
        "        x4 = Relu(self.conv64to128(x3), inplace=True)\n",
        "        x4 = Relu(self.conv128(x4), inplace=True)\n",
        "        poolX4 = self.pooling(x4)\n",
        "        #print(poolX4.shape)\n",
        "        x5 = self.dropout(poolX4)\n",
        "        #print(x5.shape)\n",
        "        x5 = Flatten(x5)\n",
        "        \n",
        "        x6 = Relu(self.linearto128(x5), inplace=True)\n",
        "        x6 = self.dropout(x6)\n",
        "        \n",
        "        #x7 = sigmoid(self.linearto1(x6))\n",
        "        x7 = self.linearto1(x6)\n",
        "        xD = data\n",
        "        #print(x7.shape, xD.shape)\n",
        "        x8 = torch.cat((x7, xD), dim=1)\n",
        "        #print(x8)\n",
        "        x9 = Relu(self.linear2to1(x8))\n",
        "        x10 = self.linear1to1(x9)\n",
        "        return x10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-z85WnQqm-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"drive/My Drive/cs-175-project/cs-175-data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaEOT9tqzPx",
        "colab_type": "code",
        "outputId": "229f61d0-3f19-4af7-a455-6521af12cb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model = Classifier();\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (convInput): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32to64): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64to128): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128to256): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv256): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv256to128): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv128to64): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv64to1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pooling2): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (upsampling): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
              "  (linearto128): Linear(in_features=2097152, out_features=128, bias=True)\n",
              "  (linearto2048): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (linearto3): Linear(in_features=2048, out_features=3, bias=True)\n",
              "  (linearto1): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (linear2to1): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (linear1to1): Linear(in_features=1, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7deG3lprGQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = PneumoniaDataset(root, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvr-6yGW4smK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = PneumoniaDataset(root, True)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-1000])\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, indices[-1000:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=1, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "lr_step = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opz_nduVr--o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_data, dtype, model, loss_fn, optimizer, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "        #print(train_data.shape)\n",
        "        for t, (image, target) in enumerate(train_data):\n",
        "            #print(image)\n",
        "            # images = list(img for img in image)\n",
        "            imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
        "            x_var = Variable(imgs.type(dtype))\n",
        "            l = []\n",
        "            metadata = []\n",
        "            for tar in target:\n",
        "              #print(tar)\n",
        "              # print(len(tar['labels']))\n",
        "              if len(tar['labels']) > 1:\n",
        "                # temp = [list(tar['labels'])[0]]\n",
        "                l.append([1])\n",
        "              else:\n",
        "                if tar['labels'] == 2:\n",
        "                  l.append([1])\n",
        "                else:\n",
        "                  l.append([0])\n",
        "              metadata.append([tar['position']])\n",
        "            # print(l)\n",
        "            y_var = torch.tensor(l).cuda() # Variable(labels.type(dtype).cuda())\n",
        "            #print(y_var)\n",
        "            \n",
        "            scores = model(imgs.cuda(), torch.tensor(metadata).cuda().float())\n",
        "            #print(scores)\n",
        "            loss = loss_fn(scores, y_var.float())\n",
        "            if (t + 1) % 100 == 0:\n",
        "              print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
        "              print(y_var)\n",
        "              print(scores)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gy3QlPBs1O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "loss_fn = nn.BCEWithLogitsLoss().type(gpu_dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Q7lCqLtguQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cba39f01-42a0-4a74-d5bc-658fcfb49917"
      },
      "source": [
        "train(data_loader, gpu_dtype, model, loss_fn, optimizer, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 1\n",
            "t = 100, loss = 1.0810\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.6666]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 200, loss = 0.4408\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[0.5907]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 300, loss = 0.9876\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.5217]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 400, loss = 0.4841\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[0.4736]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 500, loss = 0.9255\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.4207]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 600, loss = 0.8887\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.3590]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 700, loss = 0.8549\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.3009]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 800, loss = 0.5756\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[0.2508]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 900, loss = 0.6048\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[0.1852]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1000, loss = 0.7679\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.1443]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1100, loss = 0.7370\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.0858]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1200, loss = 0.7146\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[0.0425]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1300, loss = 0.6861\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.0142]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1400, loss = 0.6565\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.0746]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1500, loss = 0.6354\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.1190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1600, loss = 0.6100\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.1739]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1700, loss = 0.5853\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.2287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1800, loss = 0.8448\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.2833]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 1900, loss = 0.8692\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.3258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2000, loss = 0.8861\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.3545]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2100, loss = 0.9037\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.3844]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2200, loss = 0.5051\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.4200]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2300, loss = 0.4901\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.4581]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2400, loss = 0.9623\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.4811]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2500, loss = 0.4681\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.5159]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2600, loss = 0.4554\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.5503]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2700, loss = 0.4434\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.5835]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2800, loss = 0.4336\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.6110]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 2900, loss = 0.4279\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.6272]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3000, loss = 0.4222\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.6438]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3100, loss = 1.0890\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.6787]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3200, loss = 1.1062\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.7046]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3300, loss = 1.1189\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.7235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3400, loss = 0.3891\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.7432]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3500, loss = 0.3842\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.7585]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3600, loss = 0.3790\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.7746]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3700, loss = 0.3688\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.8074]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3800, loss = 1.1921\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.8303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 3900, loss = 0.3491\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.8727]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4000, loss = 0.3438\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.8910]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4100, loss = 1.2487\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.9106]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4200, loss = 0.3327\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.9295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4300, loss = 0.3291\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.9424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4400, loss = 0.3193\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.9778]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4500, loss = 1.3041\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-0.9875]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4600, loss = 0.3152\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-0.9929]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4700, loss = 0.3100\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0121]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4800, loss = 1.3240\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-1.0146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 4900, loss = 0.3052\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0304]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5000, loss = 0.3052\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0304]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5100, loss = 0.3024\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0410]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5200, loss = 1.3477\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-1.0469]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5300, loss = 0.3002\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0495]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5400, loss = 1.3474\n",
            "tensor([[1]], device='cuda:0')\n",
            "tensor([[-1.0464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5500, loss = 0.2975\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0598]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5600, loss = 0.2963\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0645]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5700, loss = 0.2962\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0648]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5800, loss = 0.2927\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0785]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 5900, loss = 0.2928\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0782]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 6000, loss = 0.2885\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0952]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 6100, loss = 0.2901\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0889]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "t = 6200, loss = 0.2883\n",
            "tensor([[0]], device='cuda:0')\n",
            "tensor([[-1.0963]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DiE7nPmnZDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('drive/My Drive/cs-175-project/model_checkpoints/classifier_08_13_e6.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWU4kn1TXk6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy(model, loader):\n",
        "    \"\"\"if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')\"\"\"  \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    for t, (image, target) in enumerate(loader):\n",
        "        with torch.no_grad():\n",
        "          imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
        "           # x_var = Variable(x.type(gpu_dtype))\n",
        "          l = []\n",
        "          for tar in target:\n",
        "            #print(tar)\n",
        "            if len(tar['labels']) > 1:\n",
        "              # temp = [list(tar['labels'])[0]]\n",
        "              l.append(1)\n",
        "            else:\n",
        "              if tar['labels'] == 2:\n",
        "                l.append(1)\n",
        "              else:\n",
        "                l.append(0)\n",
        "\n",
        "          l = torch.tensor(l)\n",
        "        #preds = model(imgs.cuda())\n",
        "        scores = torch.tensor([int(sigmoid(model(imgs.cuda())) > 0.45)])\n",
        "        # print(scores)\n",
        "        # print([(x, y) for x, y in zip(scores, l)])\n",
        "        # _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (scores == l).sum()\n",
        "        num_samples += scores.size(0)\n",
        "        if (t + 1) % 100 == 0:\n",
        "            print('t = %d, num_correct = %d, num_samples = %d' % (t + 1, num_correct, num_samples))\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skqwr_rfvbGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = PneumoniaDataset(root, True, 'test')\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qcj34Fan09a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_accuracy(model, data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vShcvu8EsBwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_preds(model, loader, dataset):\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    pIds = []\n",
        "    predictions = []\n",
        "    for index, (image, target) in enumerate(loader):\n",
        "        with torch.no_grad():\n",
        "          imgs = torch.tensor([img.numpy() for img in image], dtype=torch.float32)\n",
        "           # x_var = Variable(x.type(gpu_dtype))\n",
        "          \n",
        "        scores =  torch.tensor([int(sigmoid(model(imgs.cuda())) > 0.45)])\n",
        "        #_, preds = scores.data.cpu().max(1)\n",
        "        # print(preds)\n",
        "        patientId = dataset.imgs[index][:-4]\n",
        "        p = scores.numpy()[0]\n",
        "        pIds.append(patientId)\n",
        "        predictions.append(p)\n",
        "\n",
        "    #print(pIds)\n",
        "    #print(predictions)\n",
        "    d = {'patientId': pIds, 'pred': predictions}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    path = 'drive/My Drive/cs-175-project/predictions/classifier_prediction.csv'\n",
        "    df.to_csv(path, index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtoepNovuzQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_preds(model, test_data_loader, test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}